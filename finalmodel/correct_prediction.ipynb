{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOB_bzG3MzER"
      },
      "outputs": [],
      "source": [
        "#from processing import preprocess_text\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from processing1 import preprocess_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMNuQzExZ68Z",
        "outputId": "92196f12-44a5-4553-f92d-c41107c6f2c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru5K2PRANC9U",
        "outputId": "e6a7799b-2597-471b-ffb1-749dada0f3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the model with custom objects\n",
        "model = load_model('was_model.h5')\n",
        "\n",
        "with open('was_tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "with open('was_label_encoder.pickle', 'rb') as handle:\n",
        "    label_encoder = pickle.load(handle)\n",
        "\n",
        "def predict_sentiment(text_input):\n",
        "    # Preprocess the tweet\n",
        "    sequence = tokenizer.texts_to_sequences([text_input])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=50, padding='post', truncating='post')\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    print(\"Prediction Raw Output:\", prediction)\n",
        "\n",
        "    predicted_label_index = np.argmax(prediction, axis=1)[0]\n",
        "    print(\"Predicted Label Index:\", predicted_label_index)\n",
        "\n",
        "    # Decode the predicted label\n",
        "    # Define your own mapping\n",
        "    label_mapping = {'mild': 0, 'moderate': 1, 'severe': 2, 'non-depressed': 3}\n",
        "    predicted_label = list(label_mapping.keys())[list(label_mapping.values()).index(predicted_label_index)]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage\n",
        "text_input = input(\"Enter a text: \")\n",
        "\n",
        "processed_text = preprocess_text(text_input)\n",
        "\n",
        "predicted_sentiment = predict_sentiment(text_input)\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BkqtqUQM144",
        "outputId": "a37276bd-249c-492c-a2a7-ae619e72ef5f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a text: I've been feeling really low lately, and my self-esteem is almost nonexistent.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n",
            "Prediction Raw Output: [[0.03113439 0.8720187  0.05151438 0.0453325 ]]\n",
            "Predicted Label Index: 1\n",
            "Predicted Sentiment: moderate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L99iMaFlNUli"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}